{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа № 4. Нейронные сети\n",
    "\n",
    "Постройте нейросетевой классификатор для набора данных [MNIST](https://www.kaggle.com/c/digit-recognizer).\n",
    "\n",
    "## Задание\n",
    "\n",
    "1. Постройте двуслойную нейронную сеть.\n",
    "2. Постройте отчет по классификации  [classification_report](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) и матрицу ошибок [confusion_matrix](http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py)\n",
    "3. Добавьте скрытые слои и оцените как изменится качество классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "import matplotlib.image as mpimg\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import gc\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physical_devices------------- 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"physical_devices-------------\", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(physical_devices[0], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0          1       0       0       0       0       0       0       0       0   \n",
       "1          0       0       0       0       0       0       0       0       0   \n",
       "2          1       0       0       0       0       0       0       0       0   \n",
       "3          4       0       0       0       0       0       0       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "41997      7       0       0       0       0       0       0       0       0   \n",
       "41998      6       0       0       0       0       0       0       0       0   \n",
       "41999      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "41995       0  ...         0         0         0         0         0   \n",
       "41996       0  ...         0         0         0         0         0   \n",
       "41997       0  ...         0         0         0         0         0   \n",
       "41998       0  ...         0         0         0         0         0   \n",
       "41999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 785 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"train.csv\")\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "2           0       0       0       0       0       0       0       0       0   \n",
       "3           0       0       0       0       0       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995       0       0       0       0       0       0       0       0       0   \n",
       "41996       0       0       0       0       0       0       0       0       0   \n",
       "41997       0       0       0       0       0       0       0       0       0   \n",
       "41998       0       0       0       0       0       0       0       0       0   \n",
       "41999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "41995       0  ...         0         0         0         0         0   \n",
       "41996       0  ...         0         0         0         0         0   \n",
       "41997       0  ...         0         0         0         0         0   \n",
       "41998       0  ...         0         0         0         0         0   \n",
       "41999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 784 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(data_train.drop(['label'], axis = 1))\n",
    "Y_train = pd.DataFrame(data_train['label'])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "0          1\n",
       "1          0\n",
       "2          1\n",
       "3          4\n",
       "4          0\n",
       "...      ...\n",
       "41995      0\n",
       "41996      1\n",
       "41997      7\n",
       "41998      6\n",
       "41999      9\n",
       "\n",
       "[42000 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train / 255\n",
    "X_train = X_train.values.reshape(-1, 28, 28, 1)\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: \n",
      " [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.02745098 0.74117647\n",
      "  0.76862745 0.30196078 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.05490196 0.99607843\n",
      "  0.99607843 0.97254902 0.77254902 0.10196078 0.         0.\n",
      "  0.         0.         0.62352941 0.38431373 0.11372549 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.21960784 0.99607843\n",
      "  0.99607843 0.99607843 0.99607843 0.26666667 0.         0.\n",
      "  0.         0.50196078 0.97647059 0.99607843 0.8        0.27843137\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.10588235 0.90196078 0.99607843\n",
      "  0.99607843 0.99607843 0.6745098  0.06666667 0.         0.\n",
      "  0.         0.94901961 0.99607843 0.99607843 0.99607843 0.91764706\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.50196078 0.99607843 0.99607843\n",
      "  0.99607843 0.99607843 0.18823529 0.         0.         0.00392157\n",
      "  0.40392157 0.98431373 0.99607843 0.99607843 0.99607843 0.54901961\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.13333333 0.87058824 0.99607843 0.99607843\n",
      "  0.99607843 0.75686275 0.0745098  0.         0.         0.05882353\n",
      "  0.99607843 0.99607843 0.99607843 0.99607843 0.87058824 0.15294118\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.49803922 0.99607843 0.99607843 0.99607843\n",
      "  0.99607843 0.10588235 0.         0.         0.         0.56862745\n",
      "  0.99607843 0.99607843 0.99607843 0.99607843 0.29411765 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.13333333 0.8627451  0.99607843 0.99607843 0.99607843\n",
      "  0.57254902 0.00392157 0.         0.         0.05098039 0.75686275\n",
      "  0.99607843 0.99607843 0.99607843 0.89019608 0.16862745 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.49411765 0.99607843 0.99607843 0.99607843 0.99607843\n",
      "  0.07843137 0.         0.         0.         0.10980392 0.99607843\n",
      "  0.99607843 0.99607843 0.99607843 0.27058824 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.45882353 0.96862745 0.99607843 0.99607843 0.98431373 0.45098039\n",
      "  0.00784314 0.         0.         0.05490196 0.64313725 0.99607843\n",
      "  0.99607843 0.99607843 0.73333333 0.03921569 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.92156863 0.99607843 0.99607843 0.99607843 0.94509804 0.\n",
      "  0.08627451 0.19215686 0.19215686 0.63921569 0.99607843 0.99607843\n",
      "  0.99607843 0.99607843 0.67058824 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.92156863 0.99607843 0.99607843 0.99607843 0.94901961 0.39215686\n",
      "  0.8        0.99607843 1.         0.99607843 1.         0.99607843\n",
      "  0.99607843 0.95294118 0.30588235 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.90588235 0.99607843 0.99607843 0.99607843 0.99607843 0.99607843\n",
      "  0.99607843 0.99607843 0.99607843 0.99607843 0.99607843 0.99607843\n",
      "  0.99607843 0.28235294 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.19607843 0.92156863 0.99607843 0.99607843 0.99607843 0.99607843\n",
      "  0.99607843 0.99607843 0.99607843 0.99607843 0.99607843 0.99607843\n",
      "  0.75686275 0.02745098 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.61960784 0.99607843 0.99607843 0.99607843 0.99607843\n",
      "  0.81960784 0.10588235 0.82352941 0.99607843 0.99607843 0.98823529\n",
      "  0.30588235 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.03921569 0.13333333 0.50196078 0.64313725 0.13333333\n",
      "  0.0745098  0.         0.81176471 0.99607843 1.         0.97254902\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.81176471 0.99607843 0.99607843 0.54117647\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.81176471 0.99607843 0.98039216 0.36078431\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.76862745 0.99607843 0.54901961 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1254902  0.85490196 0.34901961 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[1][:, :, 0])\n",
    "print(\"Values: \\n\", X_train[1][:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Input layer\n",
    "model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#First layer\n",
    "model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#Second layer\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#OutputLayer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation = \"softmax\"))# Выбираем, какая цифра из десяти на картинке с наибольшей вероятностью\n",
    "#model.save(\"Digit_rec_model.hdf5\", include_optimizer = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/5\n",
      " - 49s - loss: 0.2578 - accuracy: 0.9485 - val_loss: 0.1273 - val_accuracy: 0.9716\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 46s - loss: 0.0852 - accuracy: 0.9819 - val_loss: 0.0949 - val_accuracy: 0.9789\n",
      "Epoch 3/5\n",
      " - 46s - loss: 0.0605 - accuracy: 0.9873 - val_loss: 0.0896 - val_accuracy: 0.9845\n",
      "Epoch 4/5\n",
      " - 46s - loss: 0.0400 - accuracy: 0.9910 - val_loss: 0.0827 - val_accuracy: 0.9851\n",
      "Epoch 5/5\n",
      " - 46s - loss: 0.0332 - accuracy: 0.9923 - val_loss: 0.0838 - val_accuracy: 0.9852\n"
     ]
    }
   ],
   "source": [
    "weights_file = \"weights.hdf5\"\n",
    "#checkpoint = ModelCheckpoint(weights_file, monitor='loss', mode='min', save_best_only=True, verbose=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "datagen = ImageDataGenerator()\n",
    "datagen.fit(X_train)\n",
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size), \n",
    "                              epochs = epochs, validation_data = (X_test,Y_test),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                              callbacks = [learning_rate_reduction] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 7, 6, ..., 2, 8, 8], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model.predict(X_test)\n",
    "predicted = np.argmax(predicted, axis = 1) \n",
    "Y_test = np.argmax(Y_test, axis = 1) \n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1028\n",
      "           1       0.99      0.99      0.99      1166\n",
      "           2       1.00      0.98      0.99      1042\n",
      "           3       0.98      0.99      0.99      1103\n",
      "           4       0.99      0.98      0.99      1028\n",
      "           5       0.98      0.98      0.98       920\n",
      "           6       0.99      0.98      0.99      1014\n",
      "           7       0.98      0.99      0.98      1144\n",
      "           8       0.97      0.99      0.98      1035\n",
      "           9       0.97      0.98      0.98      1020\n",
      "\n",
      "    accuracy                           0.99     10500\n",
      "   macro avg       0.99      0.99      0.99     10500\n",
      "weighted avg       0.99      0.99      0.99     10500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.89299611e-01 0.00000000e+00 9.72762646e-04 9.72762646e-04\n",
      "  0.00000000e+00 9.72762646e-04 1.94552529e-03 0.00000000e+00\n",
      "  3.89105058e-03 1.94552529e-03]\n",
      " [0.00000000e+00 9.90566038e-01 0.00000000e+00 2.57289880e-03\n",
      "  3.43053173e-03 0.00000000e+00 0.00000000e+00 1.71526587e-03\n",
      "  8.57632933e-04 8.57632933e-04]\n",
      " [9.59692898e-04 1.91938580e-03 9.75047985e-01 5.75815739e-03\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.05566219e-02\n",
      "  3.83877159e-03 1.91938580e-03]\n",
      " [0.00000000e+00 0.00000000e+00 9.06618314e-04 9.89120580e-01\n",
      "  0.00000000e+00 2.71985494e-03 0.00000000e+00 3.62647325e-03\n",
      "  1.81323663e-03 1.81323663e-03]\n",
      " [0.00000000e+00 2.91828794e-03 0.00000000e+00 0.00000000e+00\n",
      "  9.79571984e-01 0.00000000e+00 1.94552529e-03 0.00000000e+00\n",
      "  5.83657588e-03 9.72762646e-03]\n",
      " [2.17391304e-03 1.08695652e-03 0.00000000e+00 5.43478261e-03\n",
      "  1.08695652e-03 9.82608696e-01 2.17391304e-03 0.00000000e+00\n",
      "  4.34782609e-03 1.08695652e-03]\n",
      " [1.97238659e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  9.86193294e-04 5.91715976e-03 9.83234714e-01 0.00000000e+00\n",
      "  7.88954635e-03 0.00000000e+00]\n",
      " [2.62237762e-03 0.00000000e+00 0.00000000e+00 1.74825175e-03\n",
      "  0.00000000e+00 8.74125874e-04 0.00000000e+00 9.88636364e-01\n",
      "  1.74825175e-03 4.37062937e-03]\n",
      " [9.66183575e-04 9.66183575e-04 0.00000000e+00 1.93236715e-03\n",
      "  9.66183575e-04 1.93236715e-03 0.00000000e+00 0.00000000e+00\n",
      "  9.90338164e-01 2.89855072e-03]\n",
      " [2.94117647e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.96078431e-03 3.92156863e-03 0.00000000e+00 4.90196078e-03\n",
      "  3.92156863e-03 9.82352941e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Упрощенная модель с двумя слоями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s = Sequential()\n",
    "\n",
    "#Input layer\n",
    "model_s.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\n",
    "model_s.add(BatchNormalization())\n",
    "\n",
    "model_s.add(MaxPool2D(pool_size=(2,2)))\n",
    "model_s.add(Dropout(0.25))\n",
    "\n",
    "#OutputLayer\n",
    "model_s.add(Flatten())\n",
    "model_s.add(Dense(10, activation = \"softmax\"))# Выбираем, какая цифра из десяти на картинке с наибольшей вероятностью\n",
    "model_s.save(\"Digit_rec_model_simple.hdf5\", include_optimizer = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 18s - loss: 0.0558 - accuracy: 0.9874 - val_loss: 0.0543 - val_accuracy: 0.9867\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.05587, saving model to simple_weights.hdf5\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 18s - loss: 0.0477 - accuracy: 0.9881 - val_loss: 0.0745 - val_accuracy: 0.9803\n",
      "\n",
      "Epoch 00002: loss improved from 0.05587 to 0.04777, saving model to simple_weights.hdf5\n",
      "Epoch 3/20\n",
      " - 18s - loss: 0.0399 - accuracy: 0.9898 - val_loss: 0.0623 - val_accuracy: 0.9854\n",
      "\n",
      "Epoch 00003: loss improved from 0.04777 to 0.03997, saving model to simple_weights.hdf5\n",
      "Epoch 4/20\n",
      " - 18s - loss: 0.0373 - accuracy: 0.9907 - val_loss: 0.0568 - val_accuracy: 0.9866\n",
      "\n",
      "Epoch 00004: loss improved from 0.03997 to 0.03736, saving model to simple_weights.hdf5\n",
      "Epoch 5/20\n",
      " - 18s - loss: 0.0348 - accuracy: 0.9908 - val_loss: 0.0506 - val_accuracy: 0.9890\n",
      "\n",
      "Epoch 00005: loss improved from 0.03736 to 0.03483, saving model to simple_weights.hdf5\n",
      "Epoch 6/20\n",
      " - 18s - loss: 0.0301 - accuracy: 0.9924 - val_loss: 0.0643 - val_accuracy: 0.9878\n",
      "\n",
      "Epoch 00006: loss improved from 0.03483 to 0.03009, saving model to simple_weights.hdf5\n",
      "Epoch 7/20\n",
      " - 19s - loss: 0.0307 - accuracy: 0.9923 - val_loss: 0.0832 - val_accuracy: 0.9847\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.03009\n",
      "Epoch 8/20\n",
      " - 23s - loss: 0.0296 - accuracy: 0.9931 - val_loss: 0.0967 - val_accuracy: 0.9849\n",
      "\n",
      "Epoch 00008: loss improved from 0.03009 to 0.02960, saving model to simple_weights.hdf5\n",
      "Epoch 9/20\n",
      " - 18s - loss: 0.0301 - accuracy: 0.9931 - val_loss: 0.0678 - val_accuracy: 0.9853\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.02960\n",
      "Epoch 10/20\n",
      " - 18s - loss: 0.0244 - accuracy: 0.9946 - val_loss: 0.0803 - val_accuracy: 0.9866\n",
      "\n",
      "Epoch 00010: loss improved from 0.02960 to 0.02446, saving model to simple_weights.hdf5\n",
      "Epoch 11/20\n",
      " - 18s - loss: 0.0269 - accuracy: 0.9936 - val_loss: 0.0999 - val_accuracy: 0.9829\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.02446\n",
      "Epoch 12/20\n",
      " - 18s - loss: 0.0237 - accuracy: 0.9940 - val_loss: 0.0797 - val_accuracy: 0.9863\n",
      "\n",
      "Epoch 00012: loss improved from 0.02446 to 0.02365, saving model to simple_weights.hdf5\n",
      "Epoch 13/20\n",
      " - 18s - loss: 0.0209 - accuracy: 0.9951 - val_loss: 0.0948 - val_accuracy: 0.9852\n",
      "\n",
      "Epoch 00013: loss improved from 0.02365 to 0.02093, saving model to simple_weights.hdf5\n",
      "Epoch 14/20\n",
      " - 18s - loss: 0.0220 - accuracy: 0.9950 - val_loss: 0.1189 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.02093\n",
      "Epoch 15/20\n",
      " - 18s - loss: 0.0216 - accuracy: 0.9951 - val_loss: 0.1238 - val_accuracy: 0.9832\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.02093\n",
      "Epoch 16/20\n",
      " - 18s - loss: 0.0181 - accuracy: 0.9959 - val_loss: 0.1193 - val_accuracy: 0.9847\n",
      "\n",
      "Epoch 00016: loss improved from 0.02093 to 0.01810, saving model to simple_weights.hdf5\n",
      "Epoch 17/20\n",
      " - 19s - loss: 0.0167 - accuracy: 0.9960 - val_loss: 0.1032 - val_accuracy: 0.9867\n",
      "\n",
      "Epoch 00017: loss improved from 0.01810 to 0.01671, saving model to simple_weights.hdf5\n",
      "Epoch 18/20\n",
      " - 19s - loss: 0.0197 - accuracy: 0.9958 - val_loss: 0.1041 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.01671\n",
      "Epoch 19/20\n",
      " - 18s - loss: 0.0156 - accuracy: 0.9961 - val_loss: 0.1208 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00019: loss improved from 0.01671 to 0.01562, saving model to simple_weights.hdf5\n",
      "Epoch 20/20\n",
      " - 18s - loss: 0.0153 - accuracy: 0.9965 - val_loss: 0.1254 - val_accuracy: 0.9849\n",
      "\n",
      "Epoch 00020: loss improved from 0.01562 to 0.01529, saving model to simple_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "weights_file = \"simple_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(weights_file, monitor='val_accuracy', mode='min', save_best_only=True, verbose=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model_s.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "datagen = ImageDataGenerator()\n",
    "datagen.fit(X_train)\n",
    "history = model_s.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size), \n",
    "                              epochs = epochs, validation_data = (X_test,Y_test),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                              callbacks = [learning_rate_reduction, checkpoint] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2603"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 9, 7, ..., 6, 7, 3], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model_s.predict(X_test)\n",
    "predicted = np.argmax(predicted, axis = 1) \n",
    "Y_test = np.argmax(Y_test, axis = 1) \n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1077\n",
      "           1       1.00      0.98      0.99      1111\n",
      "           2       0.99      0.98      0.98      1055\n",
      "           3       0.96      0.99      0.98      1102\n",
      "           4       0.99      0.99      0.99      1018\n",
      "           5       0.99      0.98      0.99       971\n",
      "           6       0.99      0.99      0.99      1004\n",
      "           7       0.99      0.99      0.99      1069\n",
      "           8       0.96      0.99      0.97      1012\n",
      "           9       0.99      0.98      0.98      1081\n",
      "\n",
      "    accuracy                           0.98     10500\n",
      "   macro avg       0.99      0.98      0.98     10500\n",
      "weighted avg       0.99      0.98      0.98     10500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1063    0    0    3    0    0    1    0    9    1]\n",
      " [   0 1085    5    4    1    1    2    2   11    0]\n",
      " [   0    0 1033    8    2    0    1    4    7    0]\n",
      " [   0    0    1 1096    0    1    0    2    2    0]\n",
      " [   0    1    2    0 1007    0    3    0    1    4]\n",
      " [   1    0    0    9    0  956    1    0    4    0]\n",
      " [   1    0    0    0    3    3  993    0    4    0]\n",
      " [   1    0    3    6    3    0    0 1055    0    1]\n",
      " [   3    0    0    2    0    3    1    3  999    1]\n",
      " [   2    0    0    8    3    3    0    3    8 1054]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузим модель и веса для нее и составим отчет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "import matplotlib.image as mpimg\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import gc\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physical_devices------------- 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"physical_devices-------------\", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(physical_devices[0], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"train.csv\")\n",
    "X_train = pd.DataFrame(data_train.drop(['label'], axis = 1))\n",
    "Y_train = pd.DataFrame(data_train['label'])\n",
    "X_train = X_train / 255\n",
    "X_train = X_train.values.reshape(-1, 28, 28, 1)\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "past_model = load_model(\"model_and_weight/Digit_rec_model.hdf5\")\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "past_model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\")\n",
    "past_model.load_weights(\"model_and_weight/weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = past_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.argmax(predicted,axis = 1) \n",
    "Y_test = np.argmax(Y_test, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1015\n",
      "           1       1.00      1.00      1.00      1151\n",
      "           2       1.00      1.00      1.00      1059\n",
      "           3       1.00      1.00      1.00      1099\n",
      "           4       1.00      1.00      1.00      1037\n",
      "           5       1.00      1.00      1.00       936\n",
      "           6       1.00      1.00      1.00      1039\n",
      "           7       1.00      1.00      1.00      1125\n",
      "           8       1.00      1.00      1.00      1012\n",
      "           9       1.00      0.99      1.00      1027\n",
      "\n",
      "    accuracy                           1.00     10500\n",
      "   macro avg       1.00      1.00      1.00     10500\n",
      "weighted avg       1.00      1.00      1.00     10500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1015    0    0    0    0    0    0    0    0    0]\n",
      " [   0 1150    0    0    0    0    0    1    0    0]\n",
      " [   0    0 1059    0    0    0    0    0    0    0]\n",
      " [   0    0    0 1099    0    0    0    0    0    0]\n",
      " [   0    0    0    0 1036    0    0    0    0    1]\n",
      " [   0    0    0    0    0  935    0    0    1    0]\n",
      " [   0    0    0    0    0    0 1039    0    0    0]\n",
      " [   0    1    1    0    0    0    0 1122    1    0]\n",
      " [   0    0    0    0    0    0    0    0 1012    0]\n",
      " [   0    0    0    3    2    0    0    0    3 1019]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
